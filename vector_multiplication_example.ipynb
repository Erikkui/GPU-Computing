{"cells":[{"cell_type":"code","execution_count":208,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156671,"status":"ok","timestamp":1704709452691,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"M5VyaH-qI0c5","outputId":"5830c1fb-9983-4c88-cd50-9d79e7605df8"},"outputs":[],"source":["#!pip install pycuda # install cuda\n","import pycuda.autoinit\n","import pycuda.driver as cuda\n","from pycuda.compiler import SourceModule\n","import numpy as np\n","from timeit import default_timer as timer"]},{"cell_type":"code","execution_count":209,"metadata":{"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1704709662768,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"5mZW0etV3hl9"},"outputs":[],"source":["# CUDA kernel\n","modd = SourceModule(\"\"\"\n","__global__ void times_two(const double* A, double* B)\n","      {\n","      int index = blockIdx.x * blockDim.x + threadIdx.x;\n","      B[index] = A[index] * 2;\n","      }\n","  \"\"\")"]},{"cell_type":"code","execution_count":210,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1704709672374,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"L1Ea2UiC8EtF","outputId":"e2029b72-66f8-45ae-915a-200ab7bc21a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.01805789  3.101486    1.53857938  3.99845852  1.66500995  1.83813516\n","  1.11465302  1.34364325  1.44129155 -0.02258287]\n","[-0.01805789  3.101486    1.53857938  3.99845852  1.66500995  1.83813516\n","  1.11465302  1.34364325  1.44129155 -0.02258287]\n","Both vectors are the same.\n","GPU: 8.89999937498942e-05\n","CPU: 5.649999366141856e-05\n"]}],"source":["\n","import time\n","\n","# Create the input vectors.\n","n = 10\n","a = np.random.randn(n)\n","a = a.astype(float)\n","\n","# Allocate the memory on the GPU and copy the vectors.\n","\n","a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize) \n","cuda.memcpy_htod(a_gpu, a)\n","\n","b = np.empty_like(a)\n","b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize) # WHY NO NEED TO memcpy_htod HERE?\n","\n","# Call the CUDA kernel.\n","\n","vec_add = modd.get_function(\"times_two\")\n","\n","start_time_gpu = timer()\n","vec_add(a_gpu, b_gpu, block=(10, 1, 1), grid=(1, 1, 1))\n","time_gpu = timer() - start_time_gpu\n","\n","# Copy the result back to the host.\n","\n","cuda.memcpy_dtoh(b, b_gpu)\n","\n","a_gpu.free()\n","b_gpu.free()\n","\n","\n","# Do same calculation in CPU.\n","start_time_cpu = timer()\n","b_cpu = a * 2\n","time_cpu = timer() - start_time_cpu\n","\n","  # Verify the result\n","print(b)\n","print(b_cpu)\n","if (b_cpu == b).all():\n","  print(\"Both vectors are the same.\")\n","else:\n","  print(\"Vectors are not equal, something went wrong.\")\n","\n","print( \"GPU: \" + str( time_gpu ) )\n","print( \"CPU: \" + str( time_cpu ) )"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyORK5XTTeHJgZu4S0Q79m6w","gpuType":"T4","provenance":[{"file_id":"1o-LfY7N6YuYY2DGh9h6Lozif0Sr5HnCq","timestamp":1703053046248},{"file_id":"1rlzw0DtPEeEwtid_o02eZpewlwgdN79l","timestamp":1700218109440}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
