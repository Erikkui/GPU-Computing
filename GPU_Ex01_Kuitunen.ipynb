{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BM40A1401 GPU Computing\n","\n","## Erik Kuitunen\n","\n","### Exercise 1"]},{"cell_type":"markdown","metadata":{"id":"OqJ_QFMHgH-C"},"source":["Import needed libraries."]},{"cell_type":"code","execution_count":477,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153431,"status":"ok","timestamp":1704708100798,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"vHANHt1Pfxvy","outputId":"7bfb4420-5df9-4fe0-9b0e-e966b42e9660"},"outputs":[],"source":["#!pip install pycuda\n","import pycuda.autoinit\n","import pycuda.driver as cuda\n","from pycuda.compiler import SourceModule\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 1\n","Implement a kernel which takes two vectors A and B and adds them together to form a vector C."]},{"cell_type":"markdown","metadata":{"id":"ws4azXoLgyDV"},"source":["Derfining the kernel."]},{"cell_type":"code","execution_count":478,"metadata":{"executionInfo":{"elapsed":589,"status":"ok","timestamp":1704708787763,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"MXmfbzNGg2sN"},"outputs":[],"source":["modd = SourceModule(\"\"\"\n","  __global__ void vector_addition( double* a, double* b, double* c, int n_elem) {\n","\n","    for ( int i = threadIdx.x + blockIdx.x * blockDim.x; \n","          i < n_elem; \n","          i += gridDim.x * blockDim.x ) {\n","            \n","      c[i] = a[i] + b[i];\n","    \n","    }\n","  }\n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["Create data vectors and initalize thread and block sizes"]},{"cell_type":"code","execution_count":479,"metadata":{},"outputs":[],"source":["N = 10 ** 5\n","a = np.random.randn(N).astype( float )\n","b = np.random.randn(N).astype( float )\n","\n","block_dims = ( 1024, 1, 1 )\n","grid_dims = ( 64, 1, 1 )"]},{"cell_type":"markdown","metadata":{},"source":["Allocate memory to GPU and copy data to device"]},{"cell_type":"code","execution_count":480,"metadata":{},"outputs":[],"source":["a_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )\n","cuda.memcpy_htod( a_gpu, a )\n","\n","b_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )\n","cuda.memcpy_htod( b_gpu, b )\n","\n","c = np.empty_like(a)\n","c_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )"]},{"cell_type":"markdown","metadata":{"id":"J24uGIs1hmyU"},"source":["Calling the CUDA kernel."]},{"cell_type":"code","execution_count":481,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1704708830776,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"qKyyajYLhrT-","outputId":"c3d7fad6-cd64-4fe1-f8f5-03d907ffcd6f"},"outputs":[],"source":["kernel = modd.get_function( \"vector_addition\" )\n","\n","kernel( a_gpu, b_gpu, c_gpu, np.int32(N), block = block_dims, grid = grid_dims )"]},{"cell_type":"markdown","metadata":{},"source":["Copying the results back to host and verifying the results"]},{"cell_type":"code","execution_count":482,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The vectors are the same.\n"]}],"source":["cuda.memcpy_dtoh( c, c_gpu )\n","\n","c_cpu = a + b\n","\n","if ( c_cpu == c ).all():\n","    print( \"The vectors are the same.\" )   \n","else:\n","    print( \"The vector are not the same. Something is wrong.\" )"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 2\n","\n","Implement a kernel which multiplies two matrices together."]},{"cell_type":"markdown","metadata":{},"source":["Defining the kernel"]},{"cell_type":"code","execution_count":483,"metadata":{},"outputs":[],"source":["modd = SourceModule(\"\"\"\n","  __global__ void matrix_multiplication( const float* A, const float* B, float* C, int M, int N, int K) {\n","    \n","    int row = threadIdx.y; \n","    int col = threadIdx.x;\n","    float C_elem = 0;\n","    \n","    if ( row > M-1 || col > P-1 ) {\n","      return;\n","    }\n","    \n","    for ( int ii = 0;             \n","        ii < N; \n","        ++ii ) {\n","        \n","      float A_elem = A[ row * N + ii ];\n","      float B_elem = B[ col + P * ii ];\n","\n","      C_elem += A_elem * B_elem;\n","    \n","    }\n","    \n","    C[ col + row * P ] = C_elem;\n","    \n","  } \n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["Create data matrices and initalize thread and block sizes"]},{"cell_type":"code","execution_count":484,"metadata":{},"outputs":[],"source":["BLOCK_SIZE = 16\n","\n","M = 14   # Rows of A and C\n","N = 15   # Columns of A; rows of B\n","K = 16   # Columns of B and C\n","\n","A = np.float32( np.random.rand( M, N ) )\n","B = np.float32( np.random.rand( N, K ) )\n","\n","block_dims = ( BLOCK_SIZE, BLOCK_SIZE, 1 )\n","grid_dims = ( 1, 1, 1 )"]},{"cell_type":"markdown","metadata":{},"source":["Allocate memory and copy data from host to device "]},{"cell_type":"code","execution_count":485,"metadata":{},"outputs":[],"source":["A_gpu = cuda.mem_alloc( A.nbytes )\n","cuda.memcpy_htod( A_gpu, A )\n","\n","B_gpu = cuda.mem_alloc( B.nbytes )\n","cuda.memcpy_htod( B_gpu, B )\n","\n","C = np.empty( [ A.shape[0], B.shape[1] ], dtype = np.float32 )\n","C_gpu = cuda.mem_alloc( C.nbytes )\n"]},{"cell_type":"markdown","metadata":{},"source":["Calling the CUDA kernel."]},{"cell_type":"code","execution_count":486,"metadata":{},"outputs":[],"source":["kernel = modd.get_function( \"matrix_multiplication\" )\n","\n","kernel( A_gpu, B_gpu, C_gpu, np.int32(M), np.int32(N), np.int32(P),\n","        block = block_dims, grid = grid_dims )"]},{"cell_type":"markdown","metadata":{},"source":["Copying the results back to host and verifying the results"]},{"cell_type":"code","execution_count":487,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The result matrices are (nearly) the same.\n"]}],"source":["cuda.memcpy_dtoh( C, C_gpu )\n","\n","C_cpu = np.dot( A, B )\n","\n","C_diff = abs( C_cpu - C )\n","\n","if ( C_diff.all() < 10 ** -6 ):\n","    print( \"The result matrices are (nearly) the same.\" )   \n","else:\n","    print( \"The matrices are not the same. Something is wrong.\" )"]},{"cell_type":"markdown","metadata":{},"source":["Differences in the order of $ 10^7 $ can be found from the results. Why?\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 3\n","\n","Extend the kernel from task 2 to use shared memory."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["modd = SourceModule(\"\"\"\n","  __global__ void matmul_sharedmem( const float* A, const float* B, float* C, int block_size ) {\n","    \n","    // Block indices, each block computes submatrix of C, C_sub\n","    int block_row = blockIdx.y;\n","    int block_col = blockIdx.x;\n","    \n","    // Thread indices. Each thread computes an element of C_sub\n","    int thread_row = threadIdx.y;\n","    int thread_col = threadIdx.x;\n","    \n","    // Looping through relevant submatrices to compute C_sub\n","    for (ii)\n","    \n","    \n","    \n","  } \n","\"\"\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPpM2cfgi1eNvtNcnxiT2sO","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
