{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BM40A1401 GPU Computing\n","\n","## Erik Kuitunen\n","\n","### Exercise 1"]},{"cell_type":"markdown","metadata":{"id":"OqJ_QFMHgH-C"},"source":["Import needed libraries."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153431,"status":"ok","timestamp":1704708100798,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"vHANHt1Pfxvy","outputId":"7bfb4420-5df9-4fe0-9b0e-e966b42e9660"},"outputs":[],"source":["#!pip install pycuda\n","import pycuda.autoinit\n","import pycuda.driver as cuda\n","from pycuda.compiler import SourceModule\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 1\n","Implement a kernel which takes two vectors A and B and adds them together to form a vector C."]},{"cell_type":"markdown","metadata":{"id":"ws4azXoLgyDV"},"source":["Derfining the kernel."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":589,"status":"ok","timestamp":1704708787763,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"MXmfbzNGg2sN"},"outputs":[],"source":["modd = SourceModule(\"\"\"\n","  __global__ void vector_addition( double* a, double* b, double* c, int n_elem) {\n","\n","    for ( int i = threadIdx.x + blockIdx.x * blockDim.x; \n","          i < n_elem; \n","          i += gridDim.x * blockDim.x ) {\n","            \n","      c[i] = a[i] + b[i];\n","    \n","    }\n","  }\n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["Create data vectors and initalize thread and block sizes"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["N = 10 ** 5\n","a = np.random.randn(N).astype( float )\n","b = np.random.randn(N).astype( float )\n","\n","block_dims = ( 1024, 1, 1 )\n","grid_dims = ( 64, 1, 1 )"]},{"cell_type":"markdown","metadata":{},"source":["Allocate memory to GPU and copy data to device"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["a_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )\n","cuda.memcpy_htod( a_gpu, a )\n","\n","b_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )\n","cuda.memcpy_htod( b_gpu, b )\n","\n","c = np.empty_like(a)\n","c_gpu = cuda.mem_alloc( a.size * a.dtype.itemsize )"]},{"cell_type":"markdown","metadata":{"id":"J24uGIs1hmyU"},"source":["Calling the CUDA kernel."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1704708830776,"user":{"displayName":"Henri Petrow","userId":"15597565801323973644"},"user_tz":-120},"id":"qKyyajYLhrT-","outputId":"c3d7fad6-cd64-4fe1-f8f5-03d907ffcd6f"},"outputs":[],"source":["kernel = modd.get_function( \"vector_addition\" )\n","\n","kernel( a_gpu, b_gpu, c_gpu, np.int32(N), block = block_dims, grid = grid_dims )"]},{"cell_type":"markdown","metadata":{},"source":["Copying the results back to host and verifying the results"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The vectors are the same.\n"]}],"source":["cuda.memcpy_dtoh( c, c_gpu )\n","\n","c_cpu = a + b\n","\n","if ( c_cpu == c ).all():\n","    print( \"The vectors are the same.\" )   \n","else:\n","    print( \"The vector are not the same. Something is wrong.\" )"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 2\n","\n","Implement a kernel which multiplies two matrices together."]},{"cell_type":"markdown","metadata":{},"source":["Defining the kernel"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["modd = SourceModule(\"\"\"\n","  __global__ void matrix_multiplication( const float* A, const float* B, float* C, int M, int N, int K) {\n","    \n","    int row = threadIdx.y; \n","    int col = threadIdx.x;\n","    float C_elem = 0;\n","    \n","    if ( row > K-1 || col > K-1 ) {\n","      return;\n","    }\n","    \n","    for ( int ii = 0; ii < N; ++ii ) {\n","        \n","      float A_elem = A[ row * N + ii ];\n","      float B_elem = B[ col + K * ii ];\n","\n","      C_elem += A_elem * B_elem;\n","    \n","    }\n","    \n","    C[ col + row * K ] = C_elem;\n","    \n","  } \n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["Create data matrices and initalize thread and block sizes"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["BLOCK_SIZE = 16\n","\n","M = 14   # Rows of A and C\n","N = 15   # Columns of A; rows of B\n","K = 16   # Columns of B and C\n","\n","A = np.float32( np.random.rand( M, N ) )\n","B = np.float32( np.random.rand( N, K ) )\n","\n","block_dims = ( BLOCK_SIZE, BLOCK_SIZE, 1 )\n","grid_dims = ( 1, 1, 1 )"]},{"cell_type":"markdown","metadata":{},"source":["Allocate memory and copy data from host to device "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["A_gpu = cuda.mem_alloc( A.nbytes )\n","cuda.memcpy_htod( A_gpu, A )\n","\n","B_gpu = cuda.mem_alloc( B.nbytes )\n","cuda.memcpy_htod( B_gpu, B )\n","\n","C = np.empty( [ A.shape[0], B.shape[1] ], dtype = np.float32 )\n","C_gpu = cuda.mem_alloc( C.nbytes )\n"]},{"cell_type":"markdown","metadata":{},"source":["Calling the CUDA kernel."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["kernel = modd.get_function( \"matrix_multiplication\" )\n","\n","kernel( A_gpu, B_gpu, C_gpu, np.int32(M), np.int32(N), np.int32(K),\n","        block = block_dims, grid = grid_dims )"]},{"cell_type":"markdown","metadata":{},"source":["Copying the results back to host and verifying the results"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The result matrices are (nearly) the same.\n"]}],"source":["cuda.memcpy_dtoh( C, C_gpu )\n","\n","C_cpu = np.dot( A, B )\n","\n","C_diff = abs( C_cpu - C )\n","\n","if ( C_diff.all() < 10 ** -6 ):\n","    print( \"The result matrices are (nearly) the same.\" )   \n","else:\n","    print( \"The matrices are not the same. Something is wrong.\" )"]},{"cell_type":"markdown","metadata":{},"source":["Differences in the order of $ 10^7 $ can be found from the results. Why?\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 3\n","\n","Extend the kernel from task 2 to use shared memory."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["kernel_code_template = \"\"\"\n","  __global__ void matmul_sharedmem( const float* A, const float* B, float* C, int M, int N, int K, int n_tiles ) {\n","    \n","    float C_elem = 0;\n","    \n","    // Block indices, each block computes submatrix of C, C_sub\n","    int block_row = blockIdx.y;\n","    int block_col = blockIdx.x;\n","    \n","    // Thread indices. Each thread computes an element of C_sub\n","    int thread_row = threadIdx.y;\n","    int thread_col = threadIdx.x;\n","\n","    // Looping through relevant submatrices to compute C_sub\n","    for (int ii = 0; ii < n_tiles; ++ii ) { \n","    \n","      // Loading submatrices from global memory\n","      int linear_ind_A = N * thread_row + thread_col + ii * %(TILE_WIDTH)s + block_row * %(TILE_WIDTH)s * N;\n","      int linear_ind_B = K * thread_row + thread_col + ii * %(TILE_WIDTH)s * K + block_col * %(TILE_WIDTH)s;\n","      \n","      // Shared memory for the submatrices of A and B\n","      __shared__ float A_sub[ %(TILE_WIDTH)s ][ %(TILE_WIDTH)s ];\n","      __shared__ float B_sub[ %(TILE_WIDTH)s ][ %(TILE_WIDTH)s ];\n","      \n","      // TODO check for threads outside matrix bounds\n","      \n","      A_sub[ thread_row ][ thread_col ] = A[ linear_ind_A ];\n","      B_sub[ thread_row ][ thread_col ] = B[ linear_ind_B ];\n","      \n","      __syncthreads();\n","      \n","      // Doing the actual multiplication of the submatrices\n","      for (int kk = 0; kk < %(TILE_WIDTH)s; ++kk) {\n","        \n","        float A_sub_elem = A_sub[ thread_row ][ kk ];\n","        float B_sub_elem = B_sub[ kk ][ thread_col ];\n","        \n","        C_elem += A_sub_elem * B_sub_elem;\n","        \n","      }\n","      \n","      __syncthreads();\n","    \n","    }\n","      \n","    // Saving the C_elem to matrix C\n","    int linear_ind_C = block_row * %(TILE_WIDTH)s * K + block_col * %(TILE_WIDTH)s + thread_row * K + thread_col;\n","    C[ linear_ind_C ] = C_elem;\n","    \n","  } \n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["Create data vectors and initalize thread and block sizes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["TILE_WIDTH = 4\n","\n","M = 4\n","N = M\n","K = M\n","\n","testarr1 = np.array( [1, 1, 1, 1], dtype = np.float32 )\n","testarr2 = np.array( [1, 2, 3, 4], dtype = np.float32 )\n","A = np.array( [ 1*testarr1, 2*testarr1, 3*testarr1, 4*testarr1 ] )\n","B = np.array( [ testarr2, testarr2, testarr2, testarr2 ] )\n","\n","A = np.float32( np.random.rand( M, N ) )\n","B = np.float32( np.random.rand( N, K ) )\n","\n","gridDim = int( N/TILE_WIDTH )\n","block_dims = ( TILE_WIDTH, TILE_WIDTH, 1 )\n","grid_dims = ( gridDim, gridDim, 1 )"]},{"cell_type":"markdown","metadata":{},"source":["Allocate memory and copy data from host to device "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["A_gpu = cuda.mem_alloc( A.nbytes )\n","cuda.memcpy_htod( A_gpu, A )\n","\n","B_gpu = cuda.mem_alloc( B.nbytes )\n","cuda.memcpy_htod( B_gpu, B )\n","\n","C = np.empty( [ A.shape[0], B.shape[1] ], dtype = np.float32 )\n","C_gpu = cuda.mem_alloc( C.nbytes )"]},{"cell_type":"markdown","metadata":{},"source":["Specify constant TILE_WIDTH for the kernel. Compile and call the kernel."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\erikk\\AppData\\Local\\Temp\\ipykernel_85592\\4285599408.py:6: UserWarning: The CUDA compiler succeeded, but said the following:\n","kernel.cu\n","\n","  mod = SourceModule( kernel_code )\n"]}],"source":["kernel_code = kernel_code_template % {\n","        'TILE_WIDTH': TILE_WIDTH\n","        }\n","\n","# Compile the kernel code\n","mod = SourceModule( kernel_code )\n","\n","matrixmul = mod.get_function( \"matmul_sharedmem\" )\n","\n","matrixmul( A_gpu, B_gpu, C_gpu, np.int32(M), np.int32(N), np.int32(K), np.int32(2),\n","          block = block_dims, grid = grid_dims )"]},{"cell_type":"markdown","metadata":{},"source":["Copying the results back to host and verifying the results"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU: \n","[[1.5832738 1.5238987 1.2237086 1.2037269]\n"," [1.8890549 1.8417578 1.4358554 1.2525882]\n"," [1.0521787 1.0985444 0.6182429 0.5691301]\n"," [1.4388049 1.3882624 1.0331012 1.3743474]]\n","\n","GPU: \n","[[3.0828373 3.1578813 2.4912577 2.577466 ]\n"," [2.660978  2.5740016 2.6157286 2.259741 ]\n"," [2.2543457 2.4981287 1.5489715 1.6419407]\n"," [1.4388049 1.3882624 1.0331012 1.3743474]]\n","\n","Difference: \n","[[1.4995636 1.6339825 1.267549  1.3737391]\n"," [0.7719232 0.7322438 1.1798732 1.0071529]\n"," [1.2021669 1.3995843 0.9307286 1.0728106]\n"," [0.        0.        0.        0.       ]]\n","The result matrices are (nearly) the same.\n"]}],"source":["cuda.memcpy_dtoh( C, C_gpu )\n","\n","C_cpu = np.dot( A, B )\n","\n","print(\"CPU: \")\n","print( C_cpu)\n","\n","print( \"\\nGPU: \")\n","print( C )\n","\n","C_diff = abs( C_cpu - C )\n","print( \"\\nDifference: \")\n","print( C_diff )\n","\n","if ( C_diff.all() < 10 ** -6 ):\n","    print( \"The result matrices are (nearly) the same.\" )   \n","else:\n","    print( \"The matrices are not the same. Something is wrong.\" )"]},{"cell_type":"markdown","metadata":{},"source":["Once again differences are appearing. Seems to be related to the ratio of the size of matrix and tile width?"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPpM2cfgi1eNvtNcnxiT2sO","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
