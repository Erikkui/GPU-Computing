{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Stevens et al. Deep learning with PyTorch, Manning Publications Co, 2020\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, precision=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.423e+01, 1.710e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.000e+00, 1.320e+01, 1.780e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.000e+00, 1.316e+01, 2.360e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [3.000e+00, 1.327e+01, 4.280e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [3.000e+00, 1.317e+01, 2.590e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [3.000e+00, 1.413e+01, 4.100e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "wine_path = \"../Exercise_05/wine.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\",\", skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 14),\n",
       " ['Wine',\n",
       "  'Alcohol',\n",
       "  'Malic.acid',\n",
       "  'Ash',\n",
       "  'Acl',\n",
       "  'Mg',\n",
       "  'Phenols',\n",
       "  'Flavanoids',\n",
       "  'Nonflavanoid.phenols',\n",
       "  'Proanth',\n",
       "  'Color.int',\n",
       "  'Hue',\n",
       "  'OD',\n",
       "  'Proline'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=','))\n",
    "\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([178, 14]), torch.float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.00, 14.23,  ...,  1.04,  3.92],\n",
       "         [ 1.00, 13.20,  ...,  1.05,  3.40],\n",
       "         ...,\n",
       "         [ 3.00, 13.17,  ...,  0.60,  1.62],\n",
       "         [ 3.00, 14.13,  ...,  0.61,  1.60]]),\n",
       " torch.Size([178, 13]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1] # <1>\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1065., 1050., 1185., 1480.,  735., 1450., 1290., 1295., 1045.,\n",
       "         1045., 1510., 1280., 1320., 1150., 1547., 1310., 1280., 1130.,\n",
       "         1680.,  845.,  780.,  770., 1035., 1015.,  845.,  830., 1195.,\n",
       "         1285.,  915., 1035., 1285., 1515.,  990., 1235., 1095.,  920.,\n",
       "          880., 1105., 1020.,  760.,  795., 1035., 1095.,  680.,  885.,\n",
       "         1080., 1065.,  985., 1060., 1260., 1150., 1265., 1190., 1375.,\n",
       "         1060., 1120.,  970., 1270., 1285.,  520.,  680.,  450.,  630.,\n",
       "          420.,  355.,  678.,  502.,  510.,  750.,  718.,  870.,  410.,\n",
       "          472.,  985.,  886.,  428.,  392.,  500.,  750.,  463.,  278.,\n",
       "          714.,  630.,  515.,  520.,  450.,  495.,  562.,  680.,  625.,\n",
       "          480.,  450.,  495.,  290.,  345.,  937.,  625.,  428.,  660.,\n",
       "          406.,  710.,  562.,  438.,  415.,  672.,  315.,  510.,  488.,\n",
       "          312.,  680.,  562.,  325.,  607.,  434.,  385.,  407.,  495.,\n",
       "          345.,  372.,  564.,  625.,  465.,  365.,  380.,  380.,  378.,\n",
       "          352.,  466.,  342.,  580.,  630.,  530.,  560.,  600.,  650.,\n",
       "          695.,  720.,  515.,  580.,  590.,  600.,  780.,  520.,  550.,\n",
       "          855.,  830.,  415.,  625.,  650.,  550.,  500.,  480.,  425.,\n",
       "          675.,  640.,  725.,  480.,  880.,  660.,  620.,  520.,  680.,\n",
       "          570.,  675.,  615.,  520.,  695.,  685.,  750.,  630.,  510.,\n",
       "          470.,  660.,  740.,  750.,  835.,  840.,  560.]),\n",
       " torch.Size([178]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1] # <2>\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1065, 1050, 1185, 1480,  735, 1450, 1290, 1295, 1045, 1045, 1510,\n",
       "        1280, 1320, 1150, 1547, 1310, 1280, 1130, 1680,  845,  780,  770,\n",
       "        1035, 1015,  845,  830, 1195, 1285,  915, 1035, 1285, 1515,  990,\n",
       "        1235, 1095,  920,  880, 1105, 1020,  760,  795, 1035, 1095,  680,\n",
       "         885, 1080, 1065,  985, 1060, 1260, 1150, 1265, 1190, 1375, 1060,\n",
       "        1120,  970, 1270, 1285,  520,  680,  450,  630,  420,  355,  678,\n",
       "         502,  510,  750,  718,  870,  410,  472,  985,  886,  428,  392,\n",
       "         500,  750,  463,  278,  714,  630,  515,  520,  450,  495,  562,\n",
       "         680,  625,  480,  450,  495,  290,  345,  937,  625,  428,  660,\n",
       "         406,  710,  562,  438,  415,  672,  315,  510,  488,  312,  680,\n",
       "         562,  325,  607,  434,  385,  407,  495,  345,  372,  564,  625,\n",
       "         465,  365,  380,  380,  378,  352,  466,  342,  580,  630,  530,\n",
       "         560,  600,  650,  695,  720,  515,  580,  590,  600,  780,  520,\n",
       "         550,  855,  830,  415,  625,  650,  550,  500,  480,  425,  675,\n",
       "         640,  725,  480,  880,  660,  620,  520,  680,  570,  675,  615,\n",
       "         520,  695,  685,  750,  630,  510,  470,  660,  740,  750,  835,\n",
       "         840,  560])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 1065 is out of bounds for dimension 1 with size 178",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m target_onehot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtarget_onehot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index 1065 is out of bounds for dimension 1 with size 178"
     ]
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], data.shape[0])\n",
    "\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1065],\n",
       "        [1050],\n",
       "        [1185],\n",
       "        [1480],\n",
       "        [ 735],\n",
       "        [1450],\n",
       "        [1290],\n",
       "        [1295],\n",
       "        [1045],\n",
       "        [1045],\n",
       "        [1510],\n",
       "        [1280],\n",
       "        [1320],\n",
       "        [1150],\n",
       "        [1547],\n",
       "        [1310],\n",
       "        [1280],\n",
       "        [1130],\n",
       "        [1680],\n",
       "        [ 845],\n",
       "        [ 780],\n",
       "        [ 770],\n",
       "        [1035],\n",
       "        [1015],\n",
       "        [ 845],\n",
       "        [ 830],\n",
       "        [1195],\n",
       "        [1285],\n",
       "        [ 915],\n",
       "        [1035],\n",
       "        [1285],\n",
       "        [1515],\n",
       "        [ 990],\n",
       "        [1235],\n",
       "        [1095],\n",
       "        [ 920],\n",
       "        [ 880],\n",
       "        [1105],\n",
       "        [1020],\n",
       "        [ 760],\n",
       "        [ 795],\n",
       "        [1035],\n",
       "        [1095],\n",
       "        [ 680],\n",
       "        [ 885],\n",
       "        [1080],\n",
       "        [1065],\n",
       "        [ 985],\n",
       "        [1060],\n",
       "        [1260],\n",
       "        [1150],\n",
       "        [1265],\n",
       "        [1190],\n",
       "        [1375],\n",
       "        [1060],\n",
       "        [1120],\n",
       "        [ 970],\n",
       "        [1270],\n",
       "        [1285],\n",
       "        [ 520],\n",
       "        [ 680],\n",
       "        [ 450],\n",
       "        [ 630],\n",
       "        [ 420],\n",
       "        [ 355],\n",
       "        [ 678],\n",
       "        [ 502],\n",
       "        [ 510],\n",
       "        [ 750],\n",
       "        [ 718],\n",
       "        [ 870],\n",
       "        [ 410],\n",
       "        [ 472],\n",
       "        [ 985],\n",
       "        [ 886],\n",
       "        [ 428],\n",
       "        [ 392],\n",
       "        [ 500],\n",
       "        [ 750],\n",
       "        [ 463],\n",
       "        [ 278],\n",
       "        [ 714],\n",
       "        [ 630],\n",
       "        [ 515],\n",
       "        [ 520],\n",
       "        [ 450],\n",
       "        [ 495],\n",
       "        [ 562],\n",
       "        [ 680],\n",
       "        [ 625],\n",
       "        [ 480],\n",
       "        [ 450],\n",
       "        [ 495],\n",
       "        [ 290],\n",
       "        [ 345],\n",
       "        [ 937],\n",
       "        [ 625],\n",
       "        [ 428],\n",
       "        [ 660],\n",
       "        [ 406],\n",
       "        [ 710],\n",
       "        [ 562],\n",
       "        [ 438],\n",
       "        [ 415],\n",
       "        [ 672],\n",
       "        [ 315],\n",
       "        [ 510],\n",
       "        [ 488],\n",
       "        [ 312],\n",
       "        [ 680],\n",
       "        [ 562],\n",
       "        [ 325],\n",
       "        [ 607],\n",
       "        [ 434],\n",
       "        [ 385],\n",
       "        [ 407],\n",
       "        [ 495],\n",
       "        [ 345],\n",
       "        [ 372],\n",
       "        [ 564],\n",
       "        [ 625],\n",
       "        [ 465],\n",
       "        [ 365],\n",
       "        [ 380],\n",
       "        [ 380],\n",
       "        [ 378],\n",
       "        [ 352],\n",
       "        [ 466],\n",
       "        [ 342],\n",
       "        [ 580],\n",
       "        [ 630],\n",
       "        [ 530],\n",
       "        [ 560],\n",
       "        [ 600],\n",
       "        [ 650],\n",
       "        [ 695],\n",
       "        [ 720],\n",
       "        [ 515],\n",
       "        [ 580],\n",
       "        [ 590],\n",
       "        [ 600],\n",
       "        [ 780],\n",
       "        [ 520],\n",
       "        [ 550],\n",
       "        [ 855],\n",
       "        [ 830],\n",
       "        [ 415],\n",
       "        [ 625],\n",
       "        [ 650],\n",
       "        [ 550],\n",
       "        [ 500],\n",
       "        [ 480],\n",
       "        [ 425],\n",
       "        [ 675],\n",
       "        [ 640],\n",
       "        [ 725],\n",
       "        [ 480],\n",
       "        [ 880],\n",
       "        [ 660],\n",
       "        [ 620],\n",
       "        [ 520],\n",
       "        [ 680],\n",
       "        [ 570],\n",
       "        [ 675],\n",
       "        [ 615],\n",
       "        [ 520],\n",
       "        [ 695],\n",
       "        [ 685],\n",
       "        [ 750],\n",
       "        [ 630],\n",
       "        [ 510],\n",
       "        [ 470],\n",
       "        [ 660],\n",
       "        [ 740],\n",
       "        [ 750],\n",
       "        [ 835],\n",
       "        [ 840],\n",
       "        [ 560]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.94, 13.00,  2.34,  2.37, 19.49, 99.74,  2.30,  2.03,  0.36,\n",
       "         1.59,  5.06,  0.96,  2.61])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.01e-01, 6.59e-01, 1.25e+00, 7.53e-02, 1.12e+01, 2.04e+02,\n",
       "        3.92e-01, 9.98e-01, 1.55e-02, 3.28e-01, 5.37e+00, 5.22e-02,\n",
       "        5.04e-01])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.21,  1.51,  ...,  0.36,  1.84],\n",
       "        [-1.21,  0.25,  ...,  0.40,  1.11],\n",
       "        ...,\n",
       "        [ 1.37,  0.21,  ..., -1.56, -1.40],\n",
       "        [ 1.37,  1.39,  ..., -1.52, -1.42]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([178]), torch.bool, tensor(0))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3 # <1>\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 13])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 Wine                    nan    nan   1.94\n",
      " 1 Alcohol                 nan    nan  13.00\n",
      " 2 Malic.acid              nan    nan   2.34\n",
      " 3 Ash                     nan    nan   2.37\n",
      " 4 Acl                     nan    nan  19.49\n",
      " 5 Mg                      nan    nan  99.74\n",
      " 6 Phenols                 nan    nan   2.30\n",
      " 7 Flavanoids              nan    nan   2.03\n",
      " 8 Nonflavanoid.phenols    nan    nan   0.36\n",
      " 9 Proanth                 nan    nan   1.59\n",
      "10 Color.int               nan    nan   5.06\n",
      "11 Hue                     nan    nan   0.96\n",
      "12 OD                      nan    nan   2.61\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)] # <1>\n",
    "good_data = data[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
